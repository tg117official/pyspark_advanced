2024-12-06 09:13:20,519 - main_logger - INFO - SparkSession initialized successfully.
2024-12-06 09:13:24,653 - data_cleaning_logger - INFO - Data read from data/input/employee_new.csv successfully.
2024-12-06 09:13:24,687 - data_cleaning_logger - INFO - Data cleaned by dropping nulls and duplicates.
2024-12-06 09:13:26,528 - data_cleaning_logger - INFO - Clean data written to data/output/clean_data successfully.
2024-12-06 09:13:26,672 - transformations_logger - INFO - Clean data read from data/output/clean_data successfully.
2024-12-06 09:13:27,587 - transformations_logger - INFO - Transformation applied: Added 'total_salary' column.
2024-12-06 09:13:28,097 - main_logger - INFO - SparkSession stopped. ETL process completed.
2024-12-06 09:46:58,540 - main_logger - INFO - SparkSession initialized successfully.
2024-12-06 09:46:58,541 - utils_logger - INFO - Schema loaded and converted to StructType successfully.
2024-12-06 09:46:58,542 - main_logger - INFO - Schema loaded successfully.
2024-12-06 09:47:05,399 - data_cleaning_logger - INFO - Data read from data/input/employee_new.csv successfully.
2024-12-06 09:47:05,483 - data_cleaning_logger - ERROR - Error during data cleaning: An error occurred while calling None.org.apache.spark.api.python.PythonFunction. Trace:
py4j.Py4JException: Constructor org.apache.spark.api.python.PythonFunction([class [B, class java.util.HashMap, class java.util.ArrayList, class java.lang.String, class java.lang.String, class java.util.ArrayList, class org.apache.spark.api.python.PythonAccumulatorV2]) does not exist
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:180)
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:197)
	at py4j.Gateway.invoke(Gateway.java:237)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Unknown Source)


2024-12-06 09:47:05,483 - main_logger - CRITICAL - Critical error in ETL process: An error occurred while calling None.org.apache.spark.api.python.PythonFunction. Trace:
py4j.Py4JException: Constructor org.apache.spark.api.python.PythonFunction([class [B, class java.util.HashMap, class java.util.ArrayList, class java.lang.String, class java.lang.String, class java.util.ArrayList, class org.apache.spark.api.python.PythonAccumulatorV2]) does not exist
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:180)
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:197)
	at py4j.Gateway.invoke(Gateway.java:237)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Unknown Source)


2024-12-06 09:47:05,917 - main_logger - INFO - SparkSession stopped. ETL process completed.
2024-12-06 09:50:38,790 - main_logger - INFO - SparkSession initialized successfully.
2024-12-06 09:50:38,791 - utils_logger - INFO - Schema loaded and converted to StructType successfully.
2024-12-06 09:50:43,049 - data_cleaning_logger - INFO - Data read from data/input/employee_new.csv successfully.
2024-12-06 09:50:43,118 - data_cleaning_logger - ERROR - Error during data cleaning: An error occurred while calling None.org.apache.spark.api.python.PythonFunction. Trace:
py4j.Py4JException: Constructor org.apache.spark.api.python.PythonFunction([class [B, class java.util.HashMap, class java.util.ArrayList, class java.lang.String, class java.lang.String, class java.util.ArrayList, class org.apache.spark.api.python.PythonAccumulatorV2]) does not exist
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:180)
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:197)
	at py4j.Gateway.invoke(Gateway.java:237)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Unknown Source)


2024-12-06 09:50:43,118 - main_logger - CRITICAL - Critical error in ETL process: An error occurred while calling None.org.apache.spark.api.python.PythonFunction. Trace:
py4j.Py4JException: Constructor org.apache.spark.api.python.PythonFunction([class [B, class java.util.HashMap, class java.util.ArrayList, class java.lang.String, class java.lang.String, class java.util.ArrayList, class org.apache.spark.api.python.PythonAccumulatorV2]) does not exist
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:180)
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:197)
	at py4j.Gateway.invoke(Gateway.java:237)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Unknown Source)


2024-12-06 09:50:43,258 - main_logger - INFO - SparkSession stopped. ETL process completed.
2024-12-06 09:54:56,634 - main_logger - INFO - SparkSession initialized successfully.
2024-12-06 09:54:56,636 - utils_logger - INFO - Schema loaded and converted to StructType successfully.
2024-12-06 09:55:01,014 - data_cleaning_logger - INFO - Data read from data/input/employee_new.csv successfully.
2024-12-06 09:55:01,014 - data_cleaning_logger - ERROR - Error during data cleaning: name 'validated_df' is not defined
2024-12-06 09:55:01,014 - main_logger - CRITICAL - Critical error in ETL process: name 'validated_df' is not defined
2024-12-06 09:55:01,121 - main_logger - INFO - SparkSession stopped. ETL process completed.
2024-12-06 09:55:31,986 - main_logger - INFO - SparkSession initialized successfully.
2024-12-06 09:55:31,987 - utils_logger - INFO - Schema loaded and converted to StructType successfully.
2024-12-06 09:55:31,987 - main_logger - INFO - Schema loaded successfully. : StructType(List(StructField(id,IntegerType,true),StructField(first_name,StringType,true),StructField(last_name,StringType,true),StructField(email,StringType,true),StructField(dept,StringType,true),StructField(salary,DoubleType,true)))
2024-12-06 09:55:36,134 - data_cleaning_logger - INFO - Data read from data/input/employee_new.csv successfully.
2024-12-06 09:55:36,134 - data_cleaning_logger - ERROR - Error during data cleaning: name 'validated_df' is not defined
2024-12-06 09:55:36,134 - main_logger - CRITICAL - Critical error in ETL process: name 'validated_df' is not defined
2024-12-06 09:55:36,466 - main_logger - INFO - SparkSession stopped. ETL process completed.
2024-12-06 09:56:44,766 - main_logger - INFO - SparkSession initialized successfully.
2024-12-06 09:56:44,768 - utils_logger - INFO - Schema loaded and converted to StructType successfully.
2024-12-06 09:56:44,768 - main_logger - INFO - Schema loaded successfully. : StructType(List(StructField(id,IntegerType,true),StructField(first_name,StringType,true),StructField(last_name,StringType,true),StructField(email,StringType,true),StructField(dept,StringType,true),StructField(salary,DoubleType,true)))
2024-12-06 09:56:49,038 - data_cleaning_logger - INFO - Data read from data/input/employee_new.csv successfully.
2024-12-06 09:56:49,071 - data_cleaning_logger - INFO - Data cleaned by dropping nulls and duplicates.
2024-12-06 09:56:50,879 - data_cleaning_logger - INFO - Clean data written to data/output/clean_data successfully.
2024-12-06 09:56:51,075 - transformations_logger - INFO - Clean data read from data/output/clean_data successfully.
2024-12-06 09:56:52,422 - transformations_logger - INFO - Transformation applied: Added 'total_salary' column.
2024-12-06 09:56:52,724 - aggregations_logger - INFO - Transformed data read from data/output/aggregated_data successfully.
2024-12-06 09:56:52,901 - aggregations_logger - ERROR - Error during data aggregations: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `product_id` cannot be resolved. Did you mean one of the following? [`dept`, `id`, `email`, `salary`, `first_name`].;
'Aggregate ['product_id], ['product_id, sum('total_salary) AS total_sales#139]
+- Relation [dept#114,id#115,first_name#116,last_name#117,email#118,salary#119,avg_salary#120,salary_category#121] parquet

2024-12-06 09:56:52,906 - main_logger - CRITICAL - Critical error in ETL process: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `product_id` cannot be resolved. Did you mean one of the following? [`dept`, `id`, `email`, `salary`, `first_name`].;
'Aggregate ['product_id], ['product_id, sum('total_salary) AS total_sales#139]
+- Relation [dept#114,id#115,first_name#116,last_name#117,email#118,salary#119,avg_salary#120,salary_category#121] parquet

2024-12-06 09:56:53,316 - main_logger - INFO - SparkSession stopped. ETL process completed.
2024-12-22 10:29:07,150 - main_logger - INFO - SparkSession initialized successfully.
2024-12-22 10:29:07,151 - utils_logger - INFO - Schema loaded and converted to StructType successfully.
2024-12-22 10:29:07,151 - main_logger - INFO - Schema loaded successfully. : StructType(List(StructField(id,IntegerType,true),StructField(first_name,StringType,true),StructField(last_name,StringType,true),StructField(email,StringType,true),StructField(dept,StringType,true),StructField(salary,DoubleType,true)))
2024-12-22 10:29:11,566 - data_cleaning_logger - INFO - Data read from data/input/employee_new.csv successfully.
2024-12-22 10:29:11,566 - data_cleaning_logger - ERROR - Error during data cleaning: expected str, bytes or os.PathLike object, not StructType
2024-12-22 10:29:11,566 - main_logger - CRITICAL - Critical error in ETL process: expected str, bytes or os.PathLike object, not StructType
2024-12-22 10:29:12,003 - main_logger - INFO - SparkSession stopped. ETL process completed.
2024-12-22 10:30:29,137 - main_logger - INFO - SparkSession initialized successfully.
2024-12-22 10:30:29,138 - utils_logger - INFO - Schema loaded and converted to StructType successfully.
2024-12-22 10:30:29,138 - main_logger - INFO - Schema loaded successfully. : StructType(List(StructField(id,IntegerType,true),StructField(first_name,StringType,true),StructField(last_name,StringType,true),StructField(email,StringType,true),StructField(dept,StringType,true),StructField(salary,DoubleType,true)))
2024-12-22 10:30:33,291 - data_cleaning_logger - INFO - Data read from data/input/employee_new.csv successfully.
2024-12-22 10:30:33,292 - data_cleaning_logger - ERROR - Error during data cleaning: expected str, bytes or os.PathLike object, not StructType
2024-12-22 10:30:33,292 - main_logger - CRITICAL - Critical error in ETL process: expected str, bytes or os.PathLike object, not StructType
2024-12-22 10:30:33,637 - main_logger - INFO - SparkSession stopped. ETL process completed.
