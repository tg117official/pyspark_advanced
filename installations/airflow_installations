Airflow Installation
To install and access Apache Airflow on your EC2 instance and access it from your local computer, follow these steps:

Step 1: Update the EC2 Instance
Update the packages on your EC2 instance.


sudo apt-get update
sudo apt-get upgrade


Step 2: Install Dependencies on the EC2 Instance
Install the necessary packages on your EC2 instance.


sudo apt-get install python3-pip
sudo apt-get install libmysqlclient-dev
sudo apt-get install build-essential libssl-dev libffi-dev python3-dev


Step 3: Set Up a Python Virtual Environment (Optional but Recommended)
Creating a virtual environment will help isolate your Airflow installation.


sudo apt-get install python3-venv


Create and activate a virtual environment:


mkdir ~/airflow
cd ~/airflow
python3 -m venv airflow_venv
source airflow_venv/bin/activate


Step 4: Install Apache Airflow and Dependencies
Set the `AIRFLOW_HOME` environment variable and install Airflow.


export AIRFLOW_HOME=~/airflow
pip install apache-airflow[celery,postgres,redis]


Initialize the Airflow database:


airflow db init


Step 5: Create an Admin User
Create an admin user for Airflow:


airflow users create \
    --username admin \
    --firstname FIRSTNAME \
    --lastname LASTNAME \
    --role Admin \
    --email admin@example.com


Step 6: Configure EC2 Instance Security Group
1. Access your AWS EC2 dashboard and find the instance where you are installing Airflow.
2. Edit the Security Group attached to the EC2 instance:
    - Add a new Inbound rule with the following details:
        - Type: Custom TCP Rule
        - Protocol: TCP
        - Port range: 8080 (or the port number Airflow's webserver will use)
        - Source: Custom, and enter your local machine’s IP address (you can find your IP using `https://whatismyipaddress.com`).

   This rule will allow you to access Airflow's web interface from your local machine.

Step 7: Start the Airflow Web Server on EC2
You need to bind the web server to `0.0.0.0` so that it can be accessed externally.


airflow webserver --port 8080 --host 0.0.0.0


Step 8: Start the Scheduler on EC2
Open another terminal or use `tmux`/`screen` to run the scheduler in parallel.


airflow scheduler


Step 9: Access Airflow Web UI from Your Local Computer
Now, open your web browser and go to:


http://<your-ec2-public-ip>:8080


Replace `<your-ec2-public-ip>` with your EC2 instance's public IP address (you can find it in your EC2 dashboard under "Public IPv4 address").

You should now see the Airflow UI and be able to log in using the admin credentials you created earlier.



# Demo DAG :

To create a simple DAG in Apache Airflow that prints "Welcome to Airflow," follow these steps:

 Step 1: Navigate to the DAGs Directory
On your EC2 instance, Airflow uses the `~/airflow/dags/` directory to store DAG files by default. Navigate to this directory:


cd ~/airflow/dags


 Step 2: Create a Python File for the DAG
Create a new Python file for your DAG. Let’s name it `welcome_dag.py`.


nano welcome_dag.py


 Step 3: Write the DAG Code
Copy and paste the following Python code into the file. This DAG will have a simple task that prints "Welcome to Airflow" using a `BashOperator`.

python
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

# Default arguments for the DAG
default_args = {
    'owner': 'airflow',
    'start_date': datetime(2023, 1, 1),
    'retries': 1,
}

# Define the DAG
with DAG(
    'welcome_dag',
    default_args=default_args,
    description='A simple DAG that prints Welcome to Airflow',
    schedule_interval='@daily',  # Runs every day at midnight
    catchup=False,  # Skip backfilling for the days before the start date
) as dag:

    # Task that prints "Welcome to Airflow"
    print_welcome = BashOperator(
        task_id='print_welcome',
        bash_command='echo "Welcome to Airflow"',
    )

    # Set task dependencies (if any, for now, there's only one task)
    print_welcome


Save the file and exit the editor.

 Step 4: Verify the DAG
Once the DAG file is saved in the `~/airflow/dags/` directory, it will automatically be picked up by Airflow’s scheduler.

You can verify this by opening the Airflow web interface and checking if the new DAG `welcome_dag` appears in the DAG list.

 Step 5: Trigger the DAG from the UI
1. Open the Airflow web interface (e.g., `http://<your-ec2-public-ip>:8080`).
2. Find the `welcome_dag` in the list of DAGs.
3. Toggle the DAG to "On."
4. Trigger the DAG manually by clicking the play button (▶️).

You should be able to see the output "Welcome to Airflow" in the logs for the `print_welcome` task once the DAG runs.

 Step 6: (Optional) Run the DAG from the Command Line
Alternatively, you can run the DAG manually from the command line:


airflow dags trigger welcome_dag


This will also trigger the DAG immediately and you can check the output in the Airflow UI under the Task Instance Logs for the `print_welcome` task.
